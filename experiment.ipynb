{"cells":[{"cell_type":"markdown","metadata":{},"source":["Data and Project source: https://www.kaggle.com/competitions/gan-getting-started/overview"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","import os\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["photo_path = 'picashu/data/photo_jpg'\n","monet_path = 'picashu/data/monet_jpg'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Dataset class:\n","\n","class Images(Dataset):\n","    def __init__(self, photo_path, monet_path, transform):\n","        self.photo_path = photo_path\n","        self.monet_path = monet_path\n","        self.transform = transform\n","        self.photos = os.listdir(photo_path)\n","        self.monets = os.listdir(monet_path)\n","        self.l_photo = len(self.photos)\n","        self.l_monet = len(self.monets)\n","    \n","    def __len__(self):\n","        return max(len(self.photos), len(self.monets))\n","    \n","    def __getitem__(self, idx):\n","        photo = Image.open(self.photo_path + self.photos[idx % self.l_photo]).convert(\"RGB\")\n","        monet = Image.open(self.monet_path + self.monets[idx % self.l_monet]).convert(\"RGB\")\n","        \n","        photo = self.transform(photo)\n","        monet = self.transform(monet)\n","        \n","        return photo, monet"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define dataset:\n","\n","dataset = Images(photo_path, monet_path, transform)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define torch dataloader:\n","\n","dataloader = DataLoader(dataset, batch_size=8, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check examples of pics:\n","example = next(iter(dataloader))\n","\n","plt.subplot(1, 2, 1)\n","plt.title('Photo example')\n","plt.imshow(example[0][0].permute(1, 2, 0) * 0.5 + 0.5)\n","\n","plt.subplot(1, 2, 2)\n","plt.title('Monet example')\n","plt.imshow(example[1][0].permute(1, 2, 0) * 0.5 + 0.5)"]},{"cell_type":"markdown","metadata":{},"source":["Discriminator model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class conv_block(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels,\n","                      out_channels=out_channels, \n","                      kernel_size=4, \n","                      stride=stride,\n","                      padding=1,\n","                      bias=True,\n","                      padding_mode=\"reflect\"),\n","            nn.InstanceNorm2d(out_channels),\n","            nn.LeakyReLU(0.2)\n","        )\n","    \n","    def forward(self, x):\n","        return self.conv(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, in_channels=3):\n","        super().__init__()\n","        self.initial = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=in_channels,\n","                out_channels=64,\n","                kernel_size=4, \n","                stride=2,\n","                padding=1,\n","                padding_mode=\"reflect\"),\n","            nn.LeakyReLU(0.2)\n","        )\n","        self.process = nn.Sequential(\n","            conv_block(64, 128, 2),\n","            conv_block(128, 256, 2),\n","            conv_block(256, 512, 1),\n","            nn.Conv2d(\n","                in_channels=512,\n","                out_channels=1,\n","                kernel_size=4,\n","                stride=1,\n","                padding=1,\n","                padding_mode='reflect'),\n","            nn.Sigmoid()\n","        )\n","        \n","    def forward(self, x):\n","        \"\"\"\n","        OUT = floor((IN + 2 * padding - kernel_size + 1) / stride + 1)\n","        [batch_size, 3, 256, 256] ->\n","        [batch_size, 64, 128, 128] ->\n","        [batch_size, 128, 64, 64] ->\n","        [batch_size, 256, 32, 32] ->\n","        [batch_size, 512, 30, 30] ->\n","        [batch_size, 1, 30, 30]\n","        \"\"\"\n","        x = self.initial(x)\n","        x = self.process(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = torch.randn((1, 3, 256, 256))\n","dis = Discriminator()\n","assert(dis(x).shape == (1, 1, 30, 30))"]},{"cell_type":"markdown","metadata":{},"source":["Generator Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class gen_conv_block(nn.Module):\n","    def __init__(self, in_channels, out_channels, TYPE='down', activation=False, **kwargs):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels=in_channels,\n","                      out_channels=out_channels,\n","                      padding_mode=\"reflect\",\n","                      **kwargs) if TYPE == 'down'\n","            else nn.ConvTranspose2d(in_channels=in_channels,\n","                                   out_channels=out_channels,\n","                                   **kwargs),\n","            nn.InstanceNorm2d(out_channels),\n","            nn.ReLU(inplace=True) if activation else nn.Identity()\n","        )\n","        \n","    def forward(self, x):\n","        return self.conv(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class res_block(nn.Module):\n","    def __init__(self, channels):\n","        super().__init__()\n","        self.block_ = nn.Sequential(\n","            gen_conv_block(channels, channels, kernel_size=3, padding=1),\n","            gen_conv_block(channels, channels, activation=False, kernel_size=3, padding=1)\n","        )\n","    \n","    def forward(self, x):\n","        return x + self.block_(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, in_channels=3, num_residuals_blocks=9):\n","        super().__init__()\n","        self.initial = nn.Sequential(\n","            nn.Conv2d(in_channels, 64, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n","            nn.ReLU(inplace=True)\n","        )\n","        self.down = nn.Sequential(\n","            gen_conv_block(64, 64*2, TYPE='down', kernel_size=3, stride=2, padding=1),\n","            gen_conv_block(64*2, 64*4, TYPE='down', kernel_size=3, stride=2, padding=1)\n","        )\n","        self.residual = nn.Sequential(\n","            *[res_block(64*4) for _ in range(num_residuals_blocks)]\n","        )\n","        self.up = nn.Sequential(\n","            gen_conv_block(64*4, 64*2, TYPE='up', kernel_size=3, stride=2, padding=1, output_padding=1),\n","            gen_conv_block(64*2, 64, TYPE='up', kernel_size=3, stride=2, padding=1, output_padding=1)\n","        )\n","        self.get_img = nn.Conv2d(64, in_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n","        \n","    def forward(self, x):\n","        x = self.initial(x)\n","        x = self.down(x)\n","        x = self.residual(x)\n","        x = self.up(x)\n","        return self.get_img(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = torch.randn((1, 3, 256, 256))\n","dis = Generator()\n","assert(dis(x).shape == (1, 3, 256, 256))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lr = 2e-4\n","lambda_cycle = 10"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["disc_photo = Discriminator().to(device)\n","disc_monet = Discriminator().to(device)\n","\n","gen_photo = Generator().to(device)\n","gen_monet = Generator().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["disc_optimizer = optim.Adam(\n","    list(disc_photo.parameters()) + list(disc_monet.parameters()),\n","    lr=lr,\n","    betas=(0.5, 0.999)\n",")\n","\n","gen_optimizer = optim.Adam(\n","    list(gen_photo.parameters()) + list(gen_monet.parameters()),\n","    lr=lr,\n","    betas=(0.5, 0.999)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dis_scaler = torch.amp.GradScaler('cuda')\n","gen_scaler = torch.amp.GradScaler('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MSE = nn.MSELoss()\n","L1 = nn.L1Loss()"]},{"cell_type":"markdown","metadata":{},"source":["Training Models"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epoches = 1\n","\n","for epoch in range(epoches):\n","    running_dis_loss = 0.0\n","    running_gen_loss = 0.0\n","    for photo, monet in tqdm(dataloader, leave=True):\n","        photo = photo.to(device)\n","        monet = monet.to(device)\n","        \n","        # Train discriminator:\n","        fake_photo = gen_photo(monet)\n","        Dis_photo_real = disc_photo(photo)\n","        Dis_photo_fake = disc_photo(fake_photo.detach())\n","        \n","        Dis_photo_loss = MSE(Dis_photo_real, torch.ones_like(Dis_photo_real)) + \\\n","                         MSE(Dis_photo_fake, torch.zeros_like(Dis_photo_fake))\n","        \n","        fake_monet = gen_monet(photo)\n","        Dis_monet_real = disc_monet(monet)\n","        Dis_monet_fake = disc_monet(fake_monet.detach())\n","        \n","        Dis_monet_loss = MSE(Dis_monet_real, torch.ones_like(Dis_monet_real)) + \\\n","                         MSE(Dis_monet_fake, torch.zeros_like(Dis_monet_fake))\n","        \n","        Dis_loss = (Dis_photo_loss + Dis_monet_loss) / 2.0\n","        running_dis_loss += Dis_loss / len(dataloader)\n","        \n","        disc_optimizer.zero_grad()\n","        dis_scaler.scale(Dis_loss).backward()\n","        dis_scaler.step(disc_optimizer)\n","        dis_scaler.update()\n","        \n","        # Train Generator:\n","        Dis_photo_fake = disc_photo(fake_photo)\n","        Dis_monet_fake = disc_monet(fake_monet)\n","        \n","        Gen_photo_loss = MSE(Dis_photo_fake, torch.ones_like(Dis_photo_fake))\n","        Gen_monet_loss = MSE(Dis_monet_fake, torch.ones_like(Dis_monet_fake))\n","        \n","        Cycled_monet = gen_monet(fake_photo) \n","        Cycled_photo = gen_photo(fake_monet)\n","        \n","        Cycled_loss = L1(monet, Cycled_monet) + L1(photo, Cycled_photo)\n","        \n","        Gen_loss = Gen_photo_loss + Gen_monet_loss + Cycled_loss * lambda_cycle\n","        running_gen_loss += Gen_loss / len(dataloader)\n","        \n","        gen_optimizer.zero_grad()\n","        gen_scaler.scale(Gen_loss).backward()\n","        gen_scaler.step(gen_optimizer)\n","        gen_scaler.update()\n","    print(f\"Epoch {epoch + 1}. Generator loss by epoch: {running_gen_loss}, discriminator loss by epoch: {running_dis_loss}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.save(disc_photo.state_dict(), '/kaggle/working/disc_photo.pth')\n","torch.save(disc_monet.state_dict(), '/kaggle/working/disc_monet.pth')\n","torch.save(gen_photo.state_dict(), '/kaggle/working/gen_photo.pth')\n","torch.save(gen_monet.state_dict(), '/kaggle/working/gen_monet.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch = next(iter(dataloader))[0]\n","\n","_, ax = plt.subplots(5, 2, figsize=(12, 12))\n","\n","for i in range(5):\n","    original_img = batch[i]\n","    predicted_img = None\n","    with torch.no_grad():\n","        predicted_img = gen_monet(original_img.unsqueeze(0).to(device))\n","    \n","    ax[i, 0].imshow(original_img.permute(1, 2, 0) * 0.5 + 0.5)\n","    ax[i, 1].imshow(predicted_img.squeeze(0).permute(1, 2, 0).cpu() * 0.5 + 0.5)\n","    \n","    ax[i, 0].set_title(\"Original photo\")\n","    ax[i, 1].set_title(\"Monet like\")\n","    \n","    ax[i, 0].axis(\"off\")\n","    ax[i, 1].axis(\"off\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["This project is inspired from https://github.com/junyanz/CycleGAN"]}],"metadata":{"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":2}
